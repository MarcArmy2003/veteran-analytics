-----

# Veteran Analytics

**Core development repository for Veteran Analytics â€“ AI-powered tools and data advocacy for veterans.**

-----

### ğŸ“œ Our Mission

The **VISTA (Veteran Insights & Statistics Tool for Analysis)** project aims to build a suite of tools that help veterans and their families navigate the complexities of accessing benefits. By leveraging AI and modern data processing techniques, we transform opaque government data into an accessible, searchable, and actionable knowledge base.

-----

### âœ¨ Key Features

  * **Automated Data Processing**: Scripts that automatically clean, chunk, and structure raw government data (Excel, CSV) into formats ready for AI analysis.
  * **AI-Powered Knowledge Base**: Integration with **Google Cloud's Vertex AI** to create a powerful, searchable repository of veteran-related information.
  * **Modular GPT & Data Framework: All backend logic is organized under `src/`, with dedicated modules for ingestion (`data-loaders/`) and GPT prompt handling (`gpt-actions/`). Flask-based APIs and services, if reintroduced, will reside under `app/` for clarity and scalability.
  * **Cloud-Native Architecture**: Designed from the ground up to run on **Google Cloud Platform**, utilizing services like Cloud Run for deployment and Cloud Storage for data management.

-----

### ğŸ›ï¸ Repository Structure

This repository is a monorepo containing all the code, documentation, and assets for the Veteran Analytics project.

```plaintext
veteran-analytics/
â”œâ”€â”€ .github/                    # GitHub configuration and automation
â”‚   â””â”€â”€ workflows/              # GitHub Actions CI/CD workflows
â”œâ”€â”€ app/                        # Core application logic (e.g., UI, API, or service layer)
â”œâ”€â”€ config/                     # Project-level settings and environment configuration
â”œâ”€â”€ src/                        # Source code modules for data processing and GPT tooling
â”‚   â”œâ”€â”€ data-loaders/           # Ingestion, transformation, and preprocessing routines
â”‚   â”œâ”€â”€ gpt-actions/            # Prompt routing and GPT interaction logic
â”œâ”€â”€ docs/                       # Technical documentation, internal SOPs, and architecture records
â”œâ”€â”€ data/                       # Structured reference datasets used in development or testing
â”œâ”€â”€ assets/                     # Visual and brand assets used across the project
â”‚   â”œâ”€â”€ images/                 # Graphics, diagrams, and screenshots
â”‚   â”œâ”€â”€ logos/                  # Official logos for presentations and docs
â”œâ”€â”€ scripts/                    # Utility scripts for data processing, transformation, and repository maintenance
â”‚   â””â”€â”€ Metlakatla              # Compiled timezone data file
â”œâ”€â”€ specs/                      # API specifications, table schemas, and legacy C API interfaces
â”‚   â””â”€â”€ Apia/                   # Subfolder for schema-related or experimental specifications
â”œâ”€â”€ legal/                      # Licensing, terms of use, and compliance documentation
â”œâ”€â”€ .gitignore                  # Git exclusion rules for build, system, and binary files
â””â”€â”€ README.md                   # This file â€“ project overview and contributor instructions
```

-----

### ğŸ’» Core Technologies

This project uses a modern, scalable technology stack:

  * **Backend**: Python, Flask
  * **Data Processing**: Pandas
  * **Cloud Platform**: Google Cloud Platform (GCP)
  * **AI / RAG System**: Vertex AI Search
  * **Containerization**: Docker
  * **Deployment**: Cloud Run, Gunicorn

-----

### ğŸš€ Getting Started

The primary component of this project is the **VISTA API Backend**. For detailed instructions on how to set up the development environment, run the data processing scripts, and launch the API, please see the dedicated README file:


â¡ï¸ **[VISTA API Backend README](src/vista-api-backend/README.md)**

### ğŸ§ª Running Tests

Install the required packages using `requirements.txt` and run the automated
tests with [pytest](https://docs.pytest.org/):

```bash
pip install -r requirements.txt pytest
pytest
```

### Configuration



```yaml
paths:
  ONEDRIVE_CHATGPT_INSTRUCTIONS_DIR: /path/to/ChatGPT Instructions
  ONEDRIVE_VISTA_API_BACKEND_DIR: /path/to/ChatGPT Instructions/VISTA API Backend
  NEW_VISTA_PROJECT_ROOT: /path/to/VISTA_Project
  MARKDOWN_OUTPUT_FOLDER: /path/to/ABR Excel Table Markdowns
```

You can also set these variables directly in your shell before running any
script, for example:

```bash
export NEW_VISTA_PROJECT_ROOT=/projects/vista
```

If no values are provided, the scripts fall back to their original Windows
paths.
The API's public URL is exposed through a Cloudflare Tunnel. This URL changes
whenever you start a new tunnel. Set the `API_BASE_URL` environment variable (or
edit `.env`) to your current Cloudflare URL and update `openapi_spec.yaml`
accordingly whenever a new tunnel is created.


-----

### ğŸ“– Documentation

For a deeper dive into the project's architecture, goals, and technical implementation, please refer to our documentation.

  * **[Project Overview](docs/project-overview.md)**: A high-level summary of the project.
  * **[VISTA Codex (Knowledge Base)](docs/vista_gem_codex.md)**: The technical specifications and project memory for the VISTA system.

---
### ğŸ“˜ DAILY LOG â€“ VISTA DEVELOPMENT

â¡ï¸ [Click here for the full daily development log](docs/daily_log.md)

Includes detailed progress tracking, session notes, environment changes, file migrations, and system debugging activities.

-----

### âš–ï¸ Legal

  * **[Terms of Use](legal/TERMS.md)**
  * **[Trademark Policy](legal/TRADEMARK.md)**
